{
    "collab_server" : "",
    "contents" : "---\ntitle: \"Exercise 5\"\nauthor: \"Jai Broome\"\ndate: \"May 21, 2016\"\noutput: \n    html_document:\n        toc: true\n        number_sections: true\n---\n\n```{r}\nsource(\"ex5_chunks.R\")\nsource(\"../ex1/ex1_chunks.R\")\n```\n\n```{r dependencies, message = FALSE}\nrequire(ggplot2)\n```\nThe `.mat` files have already been read in and saved as `.csv`s since Knitr doesn't play nice with `R.matlab`.\n```{r read-data}\ntrain <- read.csv(\"../data/ex5train.csv\")\nval <- read.csv(\"../data/ex5val.csv\")\ntest <- read.csv(\"../data/ex5test.csv\")\n```\n\n# Regularized Linear Regression\n\n## Visualizing the dataset\n```{r viz-train}\ng1 <- ggplot(data = train, aes(X, y)) +\n    geom_point(shape = 4, color = \"red\", size = 3) +\n    labs(title = \"Figure 1: Training Data\", \n         x = \"Change in water level (X)\", \n         y = \"Water flowing out of the dam (y)\")\ng1\n```\n\n## Regularized linear regression cost function\n```{r ex1_chunks}\nknitr::read_chunk('../ex1/ex1_chunks.R')\n```\n```{r lin-reg-cost-func}\n```\n\n```{r gradient-check}\ncomputeCost(cbind(1, train$X), train$y, c(1,1))\n```\n\n## Fitting linear regression\n```{r ex5_chunks}\nknitr::read_chunk('ex5_chunks.R')\n```\n\n```{r trainLinearReg}\n```\n\n```{r optim}\nlearnedTheta <- trainLinearReg(cbind(1, train$X), train$y)\n```\n\n```{r plot-learnedTheta}\ng1 + geom_abline(slope = learnedTheta$par[2], intercept = learnedTheta$par[1])\n\nlm(y ~ X + 1, train)$coefficients\nlearnedTheta$par\n```\n\n`learnedTheta` matches the coefficients from `R`'s built-in linear regression function\n\n# Bias-variance\nNote that the lambda is passed as a parameter to the `learningCurve` function.\n\nWhen you are computing the training set error, make sure you compute it on the training subset (i.e., X(1:n,:) and y(1:n)) (instead of the entire training set). However, for the cross validation error, you should compute it over the entire cross validation set. You should store the computed errors in the vectors error\\_train and error\\_val.\n\n## Learning curves\n```{r learningCurve}\n```\n```{r plot-learning-curves}\nerrors <- learningCurve(cbind(1, train$X), train$y, cbind(1, val$X), val$y)\ng2 <- plotLearningCurve(errors)\ng2\n```\n\n# Polynomial regression\n```{r polyFeatures}\n```\n\n## Learning Polynomial Regression\n\n```{r featureNormalize}\n```\n```{r polyPlots}\n```\n\n```{r}\npolyPlots(train$X, train$y, val$X, val$y, n = 12, lambda = 0, p = 8)\n```\n\n## Optional (ungraded) exercise: Adjusting the regularization parameter\n\nI'll just add the optional exercises to the skeleton for now. The current plan is to finish all 8 assignments, then return to the optional exercises\n\n## Selecting Î» using a cross validation set\n\n```{r validationCurve}\n```\n```{r test-validationCurve}\nlseq <- c(0, 0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1, 3, 10)\nvCurveTrainX <- featureNormalize(polyFeatures(train$X, p = 8))\nvCurveTrainX[, 1] <- 1\nvCurveValX <- featureNormalize(polyFeatures(val$X, p = 8))\nvCurveValX[, 1] <- 1\n\nerrors <- validationCurve(vCurveTrainX, \n                          train$y, \n                          vCurveValX, \n                          val$y, \n                          lseq)\n\n# errors[, 1] <- 1:10 # for interpretability in the plot\nplotLearningCurve(errors)\n\n\n```\n\n\n",
    "created" : 1464631871215.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3830756876",
    "id" : "21F5D513",
    "lastKnownWriteTime" : 1464976572,
    "last_content_update" : 1464976572,
    "path" : "~/coursera-ml-R/ex5/ex5_solutions.Rmd",
    "project_path" : "ex5/ex5_solutions.Rmd",
    "properties" : {
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}